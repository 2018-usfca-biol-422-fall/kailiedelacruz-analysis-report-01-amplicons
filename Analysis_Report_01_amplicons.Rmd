---
title: "Analysis Report 1: Your Title Here"
author: "Kailie Dela Cruz"
date: "October 20, 2017"
output: github_document
bibliography: references.bib
csl: bioinformatics.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Introduction

Add about 1.5-2 pages here. Must cite at least 5 peer reviewed articles.

# Methods

## Sample origin and sequencing

### Sample Collection 

For the keyboard samples, Fierer et al. swabbed individual keys of three personal computer keyboards. They swabbed about 25-30 keys per keyboard. With the owners and practically sole users of each keyboard, Fierer et al. then swabbed the skin of their ventral surface of the distal joint of each fingertip. 20-35 years of age, the owners of the keyboards were healthy during the time of sampling. Before swabbing, the keyboards had not been touched for more than 30 minutes. During sampling, the three keyboards and the corresponding fingertips were swabbed within 10 minutes of each other. To understand the similarities and differences between these three keyboards in relation to other keyboards, Fierer et al. gathered samples of spacebar keys were taken from 15 other keyboards found around the University of Colorado campus. They used autoclaved cotton-tipped swabs that were pre-moistened with a sterile solution to sample the skin surfaces and keyboard keys. Each key on the keyboards were swabbed with light pressure for 10 seconds.  They then stored the swabs at -80 C for less than 1 week before DNA extraction. 

### DNA Extraction and Pyrosequencing 

Fierer et al. extracted the genomic DNA from the swabs using the MO BIO PowerSoil Isolation kit. The cotton portions of the swabs that were frozen were added into bead tubes with Solution C1. The bead tubes were incubated for 10 minutes at 65 C and then shaken for 2 minutes. Shaken by the MO BIO vortex adapter, it was done horizontally at a maximum speed. 

Fierer et al. amplified the 16SrRNA genes using the primer that is effective in phylogenetic analysis of pyrosequencing reads. They continued with polymerase chain reactions in forms of threes of 25-μL reactions with 06 μM forward and reverse primers, 3 μL template DNA and 1X of HotMasterMix. They ran thermal cycling with initial denaturation at 94 C for 3 minutes. They followed this with 35 cycles of denaturation at 94 C for 45 seconds. Annealing conditions were at 50 C for 30 seconds, extension conditions were at 72 C for 90 seconds and final extension conditions were at 72 C for 10 minutes. The replicate amplicons were cleaned using the UltraClean-htp 9g-well PCR Clean-up kit. Fierer et al. visualized the cleaned replicate amplicons on 0.1% agarose gels using SYBR Safe DNA gel stain. 

Fierer et al. carried out pyrosequencing on a 454 Life Sciences Genome Sequencer FLX instrument by the Environmental Genomics Core Facility at the University of South Carolina. 

### Sequence Analysis and Community Comparisons 

Fierer et al. removed sequences from the analysis if they were more than 300 base pairs in length, less than 200 base pairs, had a quality score of less than 25, contained unknown variables, contained an uncorrectable barcode or did not contain the primer sequence. They assigned the remaining sequences to samples by examining the 12-nt-bar code. Sequences that were similar to each other were grouped into operational taxonomic units using cd-hit. These groups had a minimum coverage of 97% and a minimum identity of 97%.  They chose representative sequences from each operational taxonomic unit by selecting the longest sequence that had the largest number of hits to other sequences in the operational taxonomic unit. Fierer et al. aligned representative sequences using NAST and the Greengenes database that had a minimum alignment length of 150 and a minimum identity of 75%. They created a phylogenetic tree using Clearcut with Kimura’s two-parameter model. 

Fierer et al. obtained a minimum of 800 quality sequences with sequences averaging 240 base pairs in length. 

To determine the amount of distance between the pairs of bacterial communities, Fierer et al. used the UniFrac metric. These distances are based on the fraction of the branch length shared between two communities within a phylogenetic tree constructed from the 16S rRNA gene sequences from all communities being compared. A small UniFrac distance means that two communities are structurally similar, where lineages share a common evolutionary history. They used the analysis of similarities function in the PRIMER program to test for differences in community structure among the groups of samples. 


## Computational

These are the methods you used. Should probably be at least a half of a page. At a very minimum should include citations for DADA2 [@callahan2016] and phyloseq [@mcmurdie2013]. Note that these don't count towards the five references you need to cite in the introduction.

# Results

## Abundance of Phylum in All Key Samples

I studied the abundance of sequences of each of the different phylum observed in all of the key samples. In analyzing the individual phylum that were gathered from the key samples, there were 7 that displayed abundance values, meaning that there are 7 different phylum found on all of the different keys. With Actinobacteria having the largest abundance of sequences at around 470-480,000, Firmicutes has the second largest abundance of sequences at around 225,000. 

```{r load-libraries, message = FALSE}
# Be sure to install these packages before running this script
# They can be installed either with the intall.packages() function
# or with the 'Packages' pane in RStudio

# load general-use packages
library("dplyr")
library("tidyr")
library("knitr")
library("ggplot2")

# this package allows for the easy inclusion of literature citations in our Rmd
# more info here: https://github.com/crsh/citr
# and here:
# http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html
library("citr")

# These are the primary packages well use to clean and analyze the data
# this package needs to be installed from bioconductor -- it's not on CRAN
# see info here: https://benjjneb.github.io/dada2/dada-installation.html
library("dada2")

# This to export a fasta of our final denoised sequence variants
library("seqinr")

# To install this you have to install from GitHub
# See more info here: https://github.com/leffj/mctoolsr
# run this -- install.packages("devtools")
# and then this -- devtools::install_github("leffj/mctoolsr")
library("mctoolsr")

# And this to visualize our results
# it also needs to be installed from bioconductor
library("phyloseq")
```

```{r extract-sample-and-file-names}
# NOTE: Much of the following follows the DADA2 tutorials available here:
# https://benjjneb.github.io/dada2/tutorial.html
# Accessed October 19, 2017

# set the base path for our input data files
path <- "data/raw_data"

# Sort ensures samples are in order
filenames_forward_reads <- sort(list.files(path, pattern = ".fastq"))

# Extract sample names, assuming filenames have format: SAMPLENAME.fastq
sample_names <- sapply(strsplit(filenames_forward_reads, "\\."), `[`, 1)

# Specify the full path to each of the filenames_forward_reads
filenames_forward_reads <- file.path(path, filenames_forward_reads)
```

```{r check-quality-plots}
# Plots the quality profiles of all twenty samples
plotQualityProfile(filenames_forward_reads[1:20])
```

We can see from the quality profiles that most reads tend to get pretty bad in quality after around 200 bases. 

```{r filter-reads}
# Place filtered files in filtered/ subdirectory
# note this will fail if the directory doesn't exist
filter_path <- file.path("output", "filtered")
filtered_reads_path <- file.path(filter_path,
                                 paste0(sample_names,
                                        "_filt.fastq.gz"))

# See ?filterAndTrim for details on the parameters
# See here for adjustments for 454 data:
# https://benjjneb.github.io/dada2/
#     faq.html#can-i-use-dada2-with-my-454-or-ion-torrent-data
filtered_output <- filterAndTrim(fwd = filenames_forward_reads,
                                 filt = filtered_reads_path,
                                 maxLen = 300,
                                 maxN = 0, # discard any seqs with Ns
                                 maxEE = 3, # allow w/ up to 3 expected errors
                                 truncQ = 2, # cut off if quality gets this low
                                 rm.phix = TRUE,
                                 compress = TRUE,
                                 multithread = FALSE)
```

```{r filtered-read-counts-table}
# produce nicely-formatted markdown table of read counts
# before/after trimming
kable(filtered_output,
      col.names = c("Reads In",
                    "Reads Out"))
```

```{r learn-errors}
# this build error models from each of the samples
errors_forward_reads <- learnErrors(filtered_reads_path,
                                    multithread = TRUE)
```

```{r visualize-errors-with-plots}
# quick check to see if error models match data
# (black lines match black points) and are generally decresing left to right
plotErrors(errors_forward_reads,
           nominalQ = TRUE)
```

```{r dereplicate-sequences}
# get rid of any duplicated sequences
dereplicated_forward_reads <- derepFastq(filtered_reads_path,
                                         verbose = TRUE)

# Name the derep-class objects by the sample names
names(dereplicated_forward_reads) <- sample_names
```

```{r run-dada}
# parameters adjusted based on recommendations for 454 data here:
# https://benjjneb.github.io/dada2/
#     faq.html#can-i-use-dada2-with-my-454-or-ion-torrent-data
dada_forward_reads <- dada(dereplicated_forward_reads,
                           err = errors_forward_reads,
                           HOMOPOLYMER_GAP_PENALTY = -1, # reduce penalty bc 454
                           BAND_SIZE = 32) # performs local alignments bc indels

# check dada results
dada_forward_reads
```

```{r make-sequence-table}
# produce the 'site by species matrix'
sequence_table <- makeSequenceTable(dada_forward_reads)
```

The output table has `r nrow(sequence_table)` rows (samples) and `r ncol(sequence_table)` columns (sequence variants). Notice how we can embed R code directly in our markdown text.

```{r histogram-of-sequence-lengths}
# Quick check to look at distribution of trimmed and denoised sequences
hist(nchar(getSequences(sequence_table)),
     main = "Histogram of final sequence variant lengths",
     xlab = "Sequence length in bp")
```

```{r remove-chimeras}
# Check for and remove chimeras
sequence_table_nochim <- removeBimeraDenovo(sequence_table,
                                            method = "consensus",
                                            multithread = FALSE,
                                            verbose = TRUE)

# What percent of our reads are non-chimeric?
non_chimeric_reads <- round(sum(sequence_table_nochim) / sum(sequence_table),
                            digits = 4) * 100
```

After removing chimeras, we were left with `r non_chimeric_reads`% of our cleaned reads.

```{r table-of-pipeline-read-counts}
# Build a table showing how many sequences remain at each step of the pipeline
get_n <- function(x) sum(getUniques(x)) # make a quick function
track <- cbind(filtered_output, # already has 2 columns
               sapply(dada_forward_reads, get_n),
               rowSums(sequence_table),
               rowSums(sequence_table_nochim))

# add nice meaningful column names
colnames(track) <- c("Input",
                     "Filtered",
                     "Denoised",
                     "Sequence Table",
                     "Non-chimeric")

# set the proper rownames
rownames(track) <- sample_names

# produce nice markdown table of progress through the pipeline
kable(track)
```

```{r assign-taxonomy}
# assigns taxonomy to each sequence variant based on a supplied training set
# made up of known sequences
taxa <- assignTaxonomy(sequence_table_nochim,
                       "data/training/rdp_train_set_16.fa.gz",
                       multithread = TRUE,
                       tryRC = TRUE) # also check with seq reverse compliments

# show the results of the taxonomy assignment
unname(taxa)
```

```{r extract-sequences-to-fasta}
# we want to export the cleaned, trimmed, filtered, denoised sequence variants
# so that we can build a phylogeny - we'll build the phylogeny outside of R
# but we need the fasta file to do so. We keep the names of each sequence as the
# sequence itself (which is rather confusing), because that's how DADA2 labels
# it's columns (e.g. 'species')
# function taken from https://github.com/benjjneb/dada2/issues/88
export_taxa_table_and_seqs <- function(sequence_table_nochim,
                                       file_seqtab,
                                       file_seqs) {
  seqtab_t <- as.data.frame(t(sequence_table_nochim)) # transpose to data frame
  seqs <- row.names(seqtab_t) # extract rownames
  row.names(seqtab_t) <- seqs # set rownames to sequences
  outlist <- list(data_loaded = seqtab_t)
  mctoolsr::export_taxa_table(outlist, file_seqtab) # write out an OTU table
  seqs <- as.list(seqs)
  seqinr::write.fasta(seqs, row.names(seqtab_t), file_seqs) # write out fasta
}

# actually run the function, with the names of the files we want it to create
# and where to put them
export_taxa_table_and_seqs(sequence_table_nochim,
                           "output/sequence_variants_table.txt",
                           "output/sequence_variants_seqs.fa")
```


```{r read-in-metadata-and-create-phyloseq}
# Next we want to read in the metadata file so we can add that in too
# This is not a csv file, so we have to use a slightly different syntax
# here the `sep = "\t"` tells the function that the data are tab-delimited
# and the `stringsAsFactors = FALSE` tells it not to assume that things are
# categorical variables
metadata_in <- read.table(paste0("data/metadata/",
                    "fierer_hand_bacteria_SRA_study_ERP022626_SraRunTable.txt"),
                          sep = "\t",
                          header = TRUE,
                          stringsAsFactors = FALSE,
                          row.names = 6) # sets sample IDs to row names

# read in the phylogeny, which was created from the fasta exported above
# in Geneious by aligning the sequences with MAFFT and then building a
# Maximum-Likelihood tree with RAxML
tree_in <- read_tree("output/sequence_variants_MAFFT_FastTree.newick")

# Construct phyloseq object (straightforward from dada2 outputs)
phyloseq_obj <- phyloseq(otu_table(sequence_table_nochim,
                                   taxa_are_rows = FALSE), # sample-spp matrix
                         sample_data(metadata_in), # metadata for each sample
                         tax_table(taxa), # taxonomy for each sequence variant
                         phy_tree(tree_in)) # phylogeny from sequence variants

# Melt all files together. This creates one overall file that
# combines all of the data from the individual files.
# Before melting, taxonomy information would be seen in a
# separate file than information about the samples.
# Using this function though, makes it so that you are
# only able to use dplyr and ggplot and not phyloseq
melted_obj <- psmelt(phyloseq_obj)
```

```{r bar-graph-1}
# This graph represents the abundance of
# each Phylum that is observed in all of the
# key samples. This gives us a general idea of
# the Phyla that we may see in graphs that look
# at specific key samples. We could have also filtered 
# finger_tip in sample_source and we would have obtained
# the same results 
melted_obj %>%
  filter(sample_type == "surface") %>%
  ggplot(aes(x = Phylum,
             y = Abundance)) +
  geom_col() +
  ggtitle("Abundance of Phylum in All Key Samples") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
**Figure 1**: The Abundance of the Different Phylum That Are Observed in All of the Key Samples 

```{r bar-graph-2}
# This bar graph goes into detail about
# the abundance of Phyla that is seen in
# the Fkey samples compared to the Jkey
# samples. Looking at the trends we can
# think about a specific Phylum that we
# want to look at
melted_obj %>%
  filter(sample_source == "Fkey" |
           sample_source == "Jkey") %>%
  ggplot(aes(x = Phylum,
             y = Abundance,
             fill = sample_source)) +
  geom_col(position = position_dodge()) +
  ggtitle("Abundance of Phylum in Fkey and Jkey Samples") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
**Figure 2**: The Abundance of the Different Phylum That Are Observed in the Fkey Samples Compared to the Jkey Samples 

```{r bar-graph-3}
# This graph takes Actinobacteria, the
# Phylum with the biggest difference between
# the Fkey and Jkey samples and looks at the
# Genus associated with it in correspondence to
# the Fkey and Jkey samples. This is why we filter the 
# Fkey, Jkey and Actinobacteria 
melted_obj %>%
  filter(sample_source == "Fkey" |
           sample_source == "Jkey") %>%
  filter(Phylum == "Actinobacteria") %>%
  ggplot(aes(x = Genus,
             y = Abundance,
             fill = sample_source)) +
  geom_col(position = position_dodge()) +
  ggtitle("Abundance of Genus in Fkey and Jkey Samples") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
**Figure 3**: The Abundance of the Different Genera That Are Observed in the Fkey Samples Compared to the Jkey Samples 

```{r bar-graph-4}
# Seeing that there is an obvious difference in
# the samples through Propionibacterium, this graph
# focuses on the abundance of Propionibacterium
# in the Fkey and Jkey samples in terms of
# the host_subject_id. M2 Corresponds to Jkey samples, 
# M3 corresponds to Jkey and Fkey samples and M9 
# corresponds to Fkey sampeles 
melted_obj %>%
  filter(Genus == "Propionibacterium") %>%
    filter(sample_source == "Fkey" |
           sample_source == "Jkey") %>%
  filter(host_subject_id == "M2" |
           host_subject_id == "M3" |
           host_subject_id == "M9") %>%
  ggplot(aes(x = host_subject_id,
             y = Abundance,
             fill = sample_source)) +
  geom_col(position = position_dodge()) +
  ggtitle("Abundance of Proponiobacterium
According to host_subject_id in Fkey and Jkey Samples") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
**Figure 4**: The Abundance of *Proponiobacterium* According to host_subject_id in the Fkey Samples Compared to the Jkey Samples 

```{r table-1}
# This table gives a summary of the results
# of the previous graph. With this, you are
# able to specifically reference the difference
# between the abundances
melted_obj %>%
  filter(Genus == "Propionibacterium") %>%
  filter(sample_source == "Fkey" |
           sample_source == "Jkey") %>%
  filter(host_subject_id == "M2" |
           host_subject_id == "M3" |
           host_subject_id == "M9") %>%
  group_by(host_subject_id, sample_source) %>%
  summarize(sum_seqs = sum(Abundance))
```
**Table 1**: A Summary of the Abundace of Sequences of *Propionibacterium* According to host_subject_id in the Fkey Samples Compared to the Jkey Samples 

# Discussion

Add around 2-3 pages interpreting your results and considering future directions one might take in analyzing these data.

# Sources Cited


